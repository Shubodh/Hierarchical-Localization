{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "import sys\n",
    "\n",
    "from hloc import extract_features, match_features, localize_inloc, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import hloc\n",
    "# print(\"carefully inspect which hloc it is, whether the docker one or normal modified one.\")\n",
    "# hloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for indoor localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Here we declare the paths to the dataset, image pairs, and we choose the feature extractor and the matcher. You need to download the [InLoc dataset](https://www.visuallocalization.net/datasets/) and put it in `datasets/inloc/`, or change the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path('datasets/inloc_small/')  # change this if your dataset is somewhere else\n",
    "\n",
    "pairs = Path('pairs/inloc_small/')\n",
    "loc_pairs = pairs / 'pairs-query-netvlad40-custom-shub-small-noDUC2.txt'  # top 40 retrieved by NetVLAD\n",
    "\n",
    "outputs = Path('outputs/inloc_small/')  # where everything will be saved\n",
    "results = outputs / 'InLoc_hloc_superpoint+superglue_netvlad40.txt'  # the result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list the standard configurations available\n",
    "# print(f'Configs for feature extractors:\\n{pformat(extract_features.confs)}')\n",
    "# print(f'Configs for feature matchers:\\n{pformat(match_features.confs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one of the configurations for extraction and matching\n",
    "# you can also simply write your own here!\n",
    "feature_conf = extract_features.confs['superpoint_inloc']\n",
    "matcher_conf = match_features.confs['superglue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract local features for database and query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/29/2021 16:16:33 INFO] Extracting local features with configuration:\n",
      "{'model': {'max_keypoints': 4096, 'name': 'superpoint', 'nms_radius': 4},\n",
      " 'output': 'feats-superpoint-n4096-r1600',\n",
      " 'preprocessing': {'grayscale': True, 'resize_max': 1600}}\n",
      "[11/29/2021 16:16:33 INFO] Found 3956 images in root datasets/inloc_small.\n",
      "[11/29/2021 16:17:13 INFO] Skipping the extraction.\n"
     ]
    }
   ],
   "source": [
    "feature_path = extract_features.main(feature_conf, dataset, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the query images\n",
    "Here we assume that the localization pairs are already computed using image retrieval (NetVLAD). To generate new pairs from your own global descriptors, have a look at `hloc/pairs_from_retrieval.py`. These pairs are also used for the localization - see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/29/2021 16:17:13 INFO] Matching local features with configuration:\n",
      "{'model': {'name': 'superglue',\n",
      "           'sinkhorn_iterations': 50,\n",
      "           'weights': 'outdoor'},\n",
      " 'output': 'matches-superglue'}\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 324559.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/29/2021 16:17:20 INFO] Finished exporting matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "match_path = match_features.main(matcher_conf, loc_pairs, feature_conf['output'], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localize!\n",
    "Perform hierarchical localization using the precomputed retrieval and matches. Different from when localizing with Aachen, here we do not need a 3D SfM model here: the dataset already has 3D lidar scans. The file `InLoc_hloc_superpoint+superglue_netvlad40.txt` will contain the estimated query poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_0_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_0_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_0_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_120_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_120_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_120_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_150_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_150_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_150_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_180_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_180_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_180_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_210_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_210_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_210_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_240_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_240_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_240_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_270_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_270_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_270_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_300_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_300_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_300_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_30_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_30_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_30_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_330_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_330_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_330_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_60_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_60_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_60_30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_90_-30.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_90_0.jpg.mat\n",
      "datasets/inloc_small/cutouts_imageonly/DUC1/010/DUC_cutout_010_90_30.jpg.mat\n",
      "len(pcd.points): 69120000\n"
     ]
    }
   ],
   "source": [
    "localize_inloc.main(\n",
    "    dataset, loc_pairs, feature_path, match_path, results,\n",
    "    skip_matches=20)  # skip database images with too few matches\n",
    "\n",
    "# DO remember skip_matches is like k2, netvlad40 is k1 where k1 is 40. That means,\n",
    "# k2 is further shortlisting these 40 images. (Following paper convention of PCLoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We parse the localization logs and for each query image plot matches and inliers with a few database images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualization.visualize_loc(results, dataset, n=1, top_k_db=1, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
